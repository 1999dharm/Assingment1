{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68edc228-02f3-4341-a33a-36147e1d2a1c",
   "metadata": {},
   "source": [
    "Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with\n",
    "an example.\n",
    "\n",
    "Ans Probability Mass Function (PMF) and Probability Density Function (PDF) are two important concepts in probability theory that are used to describe the probabilities of random variables.\n",
    "\n",
    "The PMF is used to describe the probability distribution of a discrete random variable. It is a function that assigns a probability to each possible outcome of the random variable. The sum of all the probabilities in the PMF must be equal to 1. For example, if we toss a fair coin, the PMF of the random variable X (representing the number of heads obtained) is:\n",
    "\n",
    "P(X=0) = 0.5\n",
    "P(X=1) = 0.5\n",
    "where P(X=k) denotes the probability of obtaining k heads.\n",
    "\n",
    "On the other hand, the PDF is used to describe the probability distribution of a continuous random variable. It is a function that assigns a probability density to each possible value of the random variable. The area under the PDF curve between any two values of the random variable represents the probability that the variable falls within that range. The integral of the PDF over the entire range of the random variable must be equal to 1. For example, if we measure the height of a person, the PDF of the random variable Y (representing the height) might be:\n",
    "\n",
    "f(y) = 1/170*exp(-(y-170)/30)\n",
    "where f(y) denotes the probability density of the random variable Y. In this example, the PDF is a normal distribution with mean 170 cm and standard deviation 30 cm.\n",
    "\n",
    "In summary, the PMF is used for discrete random variables, while the PDF is used for continuous random variables. Both describe the probabilities of different outcomes of the random variable, but they use different mathematical functions to do so.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fd2151-4445-4a4e-8636-eb19d360a4a1",
   "metadata": {},
   "source": [
    "Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?\n",
    "\n",
    "Ans The Cumulative Distribution Function (CDF) is a function that describes the probability that a random variable X takes on a value less than or equal to a given value x. Mathematically, the CDF of a random variable X is defined as:\n",
    "\n",
    "F(x) = P(X ≤ x)\n",
    "\n",
    "The CDF is defined for both discrete and continuous random variables. For a discrete random variable, the CDF is a step function that increases at the value of each possible outcome, while for a continuous random variable, the CDF is a continuous function.\n",
    "\n",
    "The CDF is useful because it provides a complete description of the probability distribution of a random variable. It can be used to calculate probabilities for any interval of values of the random variable, and it can be used to determine important characteristics of the distribution such as the mean, median, and mode.\n",
    "\n",
    "For example, consider the random variable X representing the number of heads obtained when tossing a fair coin three times. The PMF of X is:\n",
    "\n",
    "P(X=0) = 1/8\n",
    "P(X=1) = 3/8\n",
    "P(X=2) = 3/8\n",
    "P(X=3) = 1/8\n",
    "\n",
    "The CDF of X can be calculated by summing the probabilities of all possible outcomes less than or equal to a given value of X. For example, the CDF for X=1 is:\n",
    "\n",
    "F(1) = P(X ≤ 1) = P(X=0) + P(X=1) = 1/8 + 3/8 = 1/2\n",
    "\n",
    "The CDF for X can be graphed as a step function, where the steps are located at each possible value of X.\n",
    "\n",
    "In summary, the CDF is a function that describes the probability distribution of a random variable by providing the probability that the variable is less than or equal to a given value. It is useful for calculating probabilities for any interval of values of the random variable and for determining important characteristics of the distribution.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eed67c7-c1b2-4d14-b7c0-4336824dd980",
   "metadata": {},
   "source": [
    "Q3: What are \n",
    "some examples of situations where the normal distribution might be used as a model?\n",
    "Explain how the parameters of the normal distribution relate to the shape of the distribution.\n",
    "\n",
    "Ans The normal distribution, also known as the Gaussian distribution, is a probability distribution that is commonly used as a model for many real-world phenomena. Here are some examples of situations where the normal distribution might be used as a model:\n",
    "\n",
    "Heights and weights of individuals in a population\n",
    "Test scores and IQ scores\n",
    "Errors in measurements or observations\n",
    "Stock prices and financial returns\n",
    "Natural phenomena such as weather patterns or noise in electronic circuits\n",
    "\n",
    "The normal distribution is characterized by two parameters: the mean (μ) and the standard deviation (σ). The mean is the center of the distribution and represents the most likely value of the variable being modeled. The standard deviation is a measure of how spread out the data is from the mean. A larger standard deviation indicates that the data is more spread out, while a smaller standard deviation indicates that the data is more tightly clustered around the mean.\n",
    "\n",
    "The shape of the normal distribution is symmetric and bell-shaped, with the highest point of the curve located at the mean. The curve tapers off towards either end, approaching but never touching the x-axis. The specific shape of the curve is determined by the mean and standard deviation. As the mean changes, the entire curve shifts to the left or right. As the standard deviation changes, the curve becomes wider or narrower.\n",
    "\n",
    "The normal distribution is often used as a model because many real-world phenomena follow a pattern that is similar to the normal distribution. Additionally, the properties of the normal distribution make it mathematically tractable and easy to work with, which makes it a convenient choice for modeling data in many situations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98430273-75e2-45da-9738-7018ba34336d",
   "metadata": {},
   "source": [
    "Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal\n",
    "Distribution.\n",
    "\n",
    "\n",
    "Ans The normal distribution is one of the most important concepts in probability theory and statistics. It is a mathematical model that describes the distribution of many real-world phenomena, and it has many applications in a wide range of fields, including science, engineering, finance, and social sciences. Some of the reasons why the normal distribution is important are:\n",
    "\n",
    "It is a model for many real-world phenomena: The normal distribution is a good model for many real-world phenomena that exhibit a bell-shaped curve, such as human heights, test scores, and errors in measurements. Knowing that a data set follows a normal distribution can help us make predictions and draw conclusions about the data.\n",
    "\n",
    "It is easy to work with: The normal distribution has many mathematical properties that make it easy to work with. For example, we can use standard tables to calculate probabilities and percentiles, and we can use the central limit theorem to approximate the distribution of many other random variables.\n",
    "\n",
    "It is the foundation of statistical inference: Many statistical methods, such as hypothesis testing and confidence intervals, rely on the assumption that the data follows a normal distribution. This assumption allows us to make inferences about population parameters based on sample statistics.\n",
    "\n",
    "Here are a few real-life examples of phenomena that can be modeled using the normal distribution:\n",
    "\n",
    "Heights and weights of individuals in a population\n",
    "Test scores and IQ scores\n",
    "Annual income of a large population\n",
    "Errors in measurements or observations\n",
    "Time taken to complete a task\n",
    "In each of these examples, the normal distribution provides a good model for the data, allowing us to make predictions and draw conclusions about the population based on sample statistics.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e3f61a-3daa-4c62-ad16-2bb8a9cbd58a",
   "metadata": {},
   "source": [
    "Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli\n",
    "Distribution and Binomial Distribution?\n",
    "\n",
    "Ans The Bernoulli distribution is a probability distribution that models the outcomes of a single binary experiment, where there are only two possible outcomes, usually labeled as \"success\" and \"failure\". It is named after Swiss mathematician Jacob Bernoulli. The distribution is characterized by a single parameter, usually denoted by p, which represents the probability of success.\n",
    "\n",
    "An example of a Bernoulli experiment is flipping a coin, where success is defined as getting heads, and failure is defined as getting tails. Another example is rolling a die and defining success as rolling a specific number, such as a six, and failure as rolling any other number.\n",
    "\n",
    "The probability mass function of the Bernoulli distribution is:\n",
    "\n",
    "P(X = 1) = p and P(X = 0) = 1 - p\n",
    "\n",
    "where X is the random variable that takes on the value 1 for success and 0 for failure.\n",
    "\n",
    "The Binomial distribution, on the other hand, is a probability distribution that models the number of successes in a fixed number of independent Bernoulli trials, where each trial has the same probability of success, denoted by p. The distribution is characterized by two parameters: the number of trials n, and the probability of success p.\n",
    "\n",
    "An example of a Binomial experiment is flipping a coin 10 times and counting the number of times it comes up heads. Another example is rolling a die 20 times and counting the number of times it comes up six.\n",
    "\n",
    "The probability mass function of the Binomial distribution is:\n",
    "\n",
    "P(X = k) = (n choose k) * p^k * (1-p)^(n-k)\n",
    "\n",
    "where X is the random variable that takes on the value k, the number of successes, and \"n choose k\" represents the number of ways to choose k successes out of n trials.\n",
    "\n",
    "The main difference between the Bernoulli distribution and the Binomial distribution is that the Bernoulli distribution models a single trial with two outcomes, while the Binomial distribution models the number of successes in a fixed number of independent Bernoulli trials. In other words, the Bernoulli distribution is a special case of the Binomial distribution where n = 1.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc26300-db42-458d-9c69-f55a5b4170b1",
   "metadata": {},
   "source": [
    "Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset\n",
    "is normally distributed, what is the probability that a randomly selected observation will be greater\n",
    "than 60? Use the appropriate formula and show your calculations.\n",
    "\n",
    "Ans If we assume that the dataset is normally distributed with a mean of 50 and a standard deviation of 10, we can use the standard normal distribution to calculate the probability that a randomly selected observation will be greater than 60.\n",
    "\n",
    "First, we need to standardize the value of 60 by subtracting the mean and dividing by the standard deviation:\n",
    "\n",
    "z = (60 - 50) / 10 = 1\n",
    "\n",
    "The standardized value of 60 corresponds to a z-score of 1. We can then use a standard normal distribution table or calculator to find the probability that a randomly selected observation from a standard normal distribution will be greater than 1. The probability is:\n",
    "\n",
    "P(Z > 1) = 0.1587\n",
    "\n",
    "Therefore, the probability that a randomly selected observation from the dataset with a mean of 50 and a standard deviation of 10 will be greater than 60 is approximately 0.1587 or 15.87%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94523006-f6b8-49fa-b2e5-ffbc2d5d4587",
   "metadata": {},
   "source": [
    "Q7: Explain uniform Distribution with an example.\n",
    "\n",
    "Ans Uniform distribution is a probability distribution where every value between a certain range is equally likely to be observed. It is a continuous distribution that can be defined by two parameters: a and b, where a is the minimum value and b is the maximum value.\n",
    "\n",
    "For example, consider a situation where we roll a fair six-sided die. Each outcome (1, 2, 3, 4, 5, and 6) has an equal probability of 1/6 of occurring. This situation can be modeled using a discrete uniform distribution, where the values that the random variable can take on are 1, 2, 3, 4, 5, and 6, and each value has an equal probability of 1/6.\n",
    "\n",
    "Now, consider a situation where we want to model the waiting time for a bus at a stop. If we assume that the bus arrives at a random time between 7:00 AM and 8:00 AM, and any time between these two times is equally likely, we can use a continuous uniform distribution to model this situation. The minimum value a is 7:00 AM and the maximum value b is 8:00 AM. Any time t between these two values is equally likely to occur, and the probability density function (PDF) of the uniform distribution is:\n",
    "\n",
    "f(t) = 1 / (b - a) for a <= t <= b\n",
    "\n",
    "The PDF is a horizontal line that is constant between a and b, and equal to 1 / (b - a).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce061f66-bc39-4d6f-a66c-548df0eac3f3",
   "metadata": {},
   "source": [
    "Q8: What is the z score? State the importance of the z score.\n",
    "\n",
    "Ans The z-score, also known as the standard score, is a measure of how many standard deviations an observation or data point is away from the mean of a distribution. It is calculated by subtracting the mean of the distribution from the data point and then dividing the result by the standard deviation of the distribution.\n",
    "\n",
    "The formula for calculating the z-score is:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "where x is the data point, μ is the mean of the distribution, and σ is the standard deviation of the distribution.\n",
    "\n",
    "The importance of the z-score is that it allows us to compare data points from different distributions on a common scale. By standardizing the data points, we can compare them to the mean and standard deviation of their own distribution or to the mean and standard deviation of another distribution. This is particularly useful in statistical inference, hypothesis testing, and quality control, where we often need to compare data points from different samples or populations.\n",
    "\n",
    "For example, suppose we want to compare the test scores of two different classes of students. One class has a mean score of 75 and a standard deviation of 10, while the other class has a mean score of 80 and a standard deviation of 8. We can use the z-score to standardize the scores and compare them on a common scale:\n",
    "\n",
    "For a student who scored 85 in the first class, the z-score would be:\n",
    "\n",
    "z = (85 - 75) / 10 = 1\n",
    "\n",
    "For a student who scored 85 in the second class, the z-score would be:\n",
    "\n",
    "z = (85 - 80) / 8 = 0.625\n",
    "\n",
    "From these z-scores, we can see that a student who scored 85 in the first class performed better than a student who scored 85 in the second class, relative to their own class's mean and standard deviation.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bc0cf8-d0ae-4af3-94d6-62d59b9f11fd",
   "metadata": {},
   "source": [
    "Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem.\n",
    "\n",
    "Ans The Central Limit Theorem (CLT) is a statistical theory that states that as the sample size increases, the distribution of the sample means approaches a normal distribution, regardless of the shape of the underlying population distribution. In other words, if we take repeated random samples of size n from any population, the distribution of the sample means will be approximately normal, with a mean equal to the population mean and a standard deviation equal to the population standard deviation divided by the square root of n.\n",
    "\n",
    "The significance of the Central Limit Theorem is that it allows us to make inferences about the population mean and standard deviation based on sample statistics. Specifically, it provides a basis for hypothesis testing and confidence interval estimation.\n",
    "\n",
    "For example, suppose we want to estimate the mean height of all students in a university. We could take a random sample of 100 students and calculate the sample mean height. If we assume that the population distribution of heights is not normal, the Central Limit Theorem tells us that the distribution of the sample means will still be approximately normal. We can then use this normal distribution to calculate a confidence interval for the population mean height or to test a hypothesis about the population mean height.\n",
    "\n",
    "The Central Limit Theorem is also important in quality control, where it allows us to monitor the process mean and detect whether it has shifted from a target value. By taking repeated samples of the process and calculating the sample means, we can use the Central Limit Theorem to construct control charts and monitor the process mean over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc896b30-1291-477e-93bb-699f3f3c0a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q10: State the assumptions of the Central Limit Theorem.\n",
    "\n",
    "Ans "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
